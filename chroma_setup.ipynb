{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Manual ChromaDB Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import chromadb\n",
    "\n",
    "# Create a persistent client\n",
    "client = chromadb.PersistentClient(path=\"./chroma_db\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert PDF to Text\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "def load_pdf(pdf_path):\n",
    "    \"\"\"\n",
    "    Load a PDF file and convert to text documents\n",
    "    \n",
    "    Args:\n",
    "        pdf_path (str): Path to PDF file\n",
    "        \n",
    "    Returns:\n",
    "        list: List of document pages\n",
    "    \"\"\"\n",
    "    loader = PyPDFLoader(pdf_path)\n",
    "    pages = loader.load()\n",
    "    return pages\n",
    "\n",
    "def create_chunks(documents, chunk_size=800, chunk_overlap=200):\n",
    "    \"\"\"\n",
    "    Split documents into overlapping chunks\n",
    "    \n",
    "    Args:\n",
    "        documents (list): List of documents to split\n",
    "        chunk_size (int): Size of each chunk in characters\n",
    "        chunk_overlap (int): Number of characters to overlap between chunks\n",
    "        \n",
    "    Returns:\n",
    "        list: List of text chunks\n",
    "    \"\"\"\n",
    "    text_splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=chunk_size,\n",
    "        chunk_overlap=chunk_overlap,\n",
    "        length_function=len,\n",
    "        is_separator_regex=False,\n",
    "    )\n",
    "    \n",
    "    chunks = text_splitter.split_documents(documents)\n",
    "    return chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and Chunk the PDF\n",
    "pdf_path = \"./testing/ft_guide.pdf\"\n",
    "documents = load_pdf(pdf_path)\n",
    "chunks = create_chunks(documents)\n",
    "\n",
    "# Create a collection with OpenAI embeddings\n",
    "from chromadb.utils.embedding_functions import OpenAIEmbeddingFunction\n",
    "\n",
    "# API Key from Env\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "\n",
    "embedding_function = OpenAIEmbeddingFunction(\n",
    "    api_key=OPENAI_API_KEY,\n",
    "    model_name=\"text-embedding-3-small\"  # Latest OpenAI embedding model\n",
    ")\n",
    "\n",
    "collection = client.create_collection(\n",
    "    name=\"pdf_collection\",\n",
    "    embedding_function=embedding_function\n",
    ")\n",
    "\n",
    "# Add documents to collection\n",
    "documents = [chunk.page_content for chunk in chunks]\n",
    "metadatas = [chunk.metadata for chunk in chunks]\n",
    "ids = [str(i) for i in range(len(chunks))]\n",
    "\n",
    "# Add to collection\n",
    "collection.add(\n",
    "    documents=documents,\n",
    "    metadatas=metadatas,\n",
    "    ids=ids\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "555"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get Statistics about the collection size\n",
    "collection.count()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Query Results:\n",
      "--------------------------------------------------\n",
      "\n",
      "Result 1\n",
      "Distance Score: 0.9746\n",
      "Document Content: – Cloud AI API: Offers APIs for NLP tasks such as translation, sentiment analysis, and\n",
      "entity recognition. These APIs are backed by Google’s powerful infrastructure, ensuring high\n",
      "performance and reliability.\n",
      "– Tutorial: This document contains a tutorial for training and deploying an LLM in GCP.\n",
      "• Hugging Face\n",
      "– Inference API: This service allows users to deploy and manage LLMs hosted on Hugging\n",
      "Face’s infrastructure. It supports various models from the Transformers library and provides\n",
      "an easy-to-use API for integrating these models into applications.\n",
      "– Spaces: A collaborative environment where users can deploy and share models using Hugging\n",
      "Face’s hosting platform. It supports deploying custom models and interactive demos.\n",
      "--------------------------------------------------\n",
      "\n",
      "Result 2\n",
      "Distance Score: 1.0330\n",
      "Document Content: – Azure Machine Learning: Supports the deployment of custom and pre-trained models,\n",
      "offering tools for model management, deployment, and monitoring. It integrates with Azure’s\n",
      "broader ecosystem for scalable and secure ML operations.\n",
      "– Tutorial: Here is the tutorial for creating and deploying an Azure OpenAI Service in Mi-\n",
      "crosoft Azure platform.\n",
      "• Google Cloud Platform (GCP)\n",
      "– Vertex AI: This platform allows the deployment of large language models with tools for\n",
      "training, tuning, and serving models. Vertex AI supports models like BERT and GPT-3,\n",
      "providing extensive MLOps capabilities for end-to-end management.\n",
      "– Cloud AI API: Offers APIs for NLP tasks such as translation, sentiment analysis, and\n",
      "entity recognition. These APIs are backed by Google’s powerful infrastructure, ensuring high\n",
      "--------------------------------------------------\n",
      "\n",
      "Result 3\n",
      "Distance Score: 1.0970\n",
      "Document Content: services.\n",
      "Deployed within\n",
      "custom infrastruc-\n",
      "ture; integrates with\n",
      "various cloud and\n",
      "on-premises services.\n",
      "Integration with\n",
      "Ecosystem\n",
      "Limited to OpenAI\n",
      "ecosystem; integrates\n",
      "well with apps via\n",
      "API.\n",
      "Seamless integration\n",
      "with Google Cloud\n",
      "services (e.g., Big-\n",
      "Query, AutoML).\n",
      "Deep integration with\n",
      "Azure’s services (e.g.,\n",
      "Data Factory, Power\n",
      "BI).\n",
      "Flexible integration\n",
      "with multiple tools,\n",
      "APIs, and data\n",
      "sources.\n",
      "Data Privacy Managed by OpenAI;\n",
      "users must consider\n",
      "data transfer and pri-\n",
      "vacy implications.\n",
      "Strong privacy and\n",
      "security measures\n",
      "within Google Cloud\n",
      "environment.\n",
      "Strong privacy and\n",
      "security measures\n",
      "within Azure envi-\n",
      "ronment.\n",
      "Dependent on the in-\n",
      "tegrations and infras-\n",
      "tructure used; users\n",
      "manage privacy.\n",
      "Target Users Developers and en-\n",
      "terprises looking\n",
      "for straightforward,\n",
      "--------------------------------------------------\n",
      "\n",
      "Result 4\n",
      "Distance Score: 1.1164\n",
      "Document Content: with high-performance hardware such as GPUs (Graphics Processing Units) or TPUs (Tensor Processing\n",
      "Units). GPUs, such as the NVIDIA A100 or V100, are widely used for training deep learning models\n",
      "due to their parallel processing capabilities. For larger-scale operations, TPUs offered by Google Cloud\n",
      "can provide even greater acceleration [44].\n",
      "First, ensure that your system or cloud environment has the necessary hardware installed. For GPUs,\n",
      "this involves setting up CUDA1 (Compute Unified Device Architecture) and cuDNN2 (CUDA Deep Neu-\n",
      "ral Network library) from NVIDIA, which are essential for enabling GPU acceleration. For TPU usage,\n",
      "you would typically set up a Google Cloud environment with TPU instances, which includes configuring\n",
      "the TPU runtime in your training scripts.\n",
      "--------------------------------------------------\n",
      "\n",
      "Result 5\n",
      "Distance Score: 1.1382\n",
      "Document Content: security measures\n",
      "within Azure envi-\n",
      "ronment.\n",
      "Dependent on the in-\n",
      "tegrations and infras-\n",
      "tructure used; users\n",
      "manage privacy.\n",
      "Target Users Developers and en-\n",
      "terprises looking\n",
      "for straightforward,\n",
      "API-based LLM\n",
      "fine-tuning.\n",
      "Developers and busi-\n",
      "nesses integrated into\n",
      "Google Cloud or seek-\n",
      "ing to leverage GCP.\n",
      "Enterprises and de-\n",
      "velopers integrated\n",
      "into Azure or seeking\n",
      "to leverage Azure’s\n",
      "AI tools.\n",
      "Developers needing\n",
      "to build complex,\n",
      "modular LLM-based\n",
      "applications with\n",
      "custom workflows.\n",
      "Limitations Limited customisa-\n",
      "tion; dependency on\n",
      "OpenAI’s infrastruc-\n",
      "ture; potential cost.\n",
      "Limited to Google\n",
      "Cloud ecosystem; po-\n",
      "tential cost and ven-\n",
      "dor lock-in.\n",
      "Limited to Azure\n",
      "ecosystem; potential\n",
      "cost and vendor\n",
      "lock-in.\n",
      "Complexity in chain-\n",
      "ing multiple models\n",
      "and data sources; re-\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Query Function\n",
    "results = collection.query(\n",
    "    query_texts=[\"google cloud platform virtual machine\"],\n",
    "    n_results=5\n",
    ")\n",
    "\n",
    "\n",
    "# Print Results Stylized\n",
    "print(\"\\nQuery Results:\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "for i, (doc, distance) in enumerate(zip(results['documents'][0], results['distances'][0])):\n",
    "    print(f\"\\nResult {i+1}\")\n",
    "    print(f\"Distance Score: {distance:.4f}\")  # Show raw distance score\n",
    "    print(f\"Document Content: {doc}\")  # Show full document\n",
    "    print(\"-\" * 50)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
